#!/usr/bin/env python3
"""
ETF/æŒ‡æ•°æ± æ›´æ–°å·¥å…·
è·å–æ‰€æœ‰ETFå’ŒæŒ‡æ•°ï¼Œä¿å­˜åˆ°config/universe.csv
"""

import os
import pandas as pd
import tushare as ts
import logging
import time
from dotenv import load_dotenv
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡å¹¶åˆå§‹åŒ–Tushare
load_dotenv()
pro = ts.pro_api(os.getenv("TUSHARE_TOKEN"))

def get_all_etfs():
    """è·å–æ‰€æœ‰ETF"""
    try:
        etf_basic = pro.fund_basic(market='E')
        time.sleep(1.2)  # APIé¢‘ç‡æ§åˆ¶ï¼šæ¯åˆ†é’Ÿä¸è¶…è¿‡50æ¬¡
        if etf_basic.empty:
            return pd.DataFrame()
        
        etf_list = []
        for _, etf in etf_basic.iterrows():
            etf_list.append({
                'ts_code': etf['ts_code'],
                'name': etf['name'],
                'target_type': 'ETF',
                'category': 'ETF'
            })
        
        logger.info(f"è·å–åˆ° {len(etf_list)} åªETF")
        return pd.DataFrame(etf_list)
        
    except Exception as e:
        logger.error(f"è·å–ETFåˆ—è¡¨å¤±è´¥: {e}")
        return pd.DataFrame()

def get_all_indices():
    """è·å–æ‰€æœ‰æŒ‡æ•°ï¼ˆåŒ…æ‹¬SSEã€SZSEã€CSIã€CNIï¼‰"""
    all_indices = []
    
    # ä¸Šäº¤æ‰€æŒ‡æ•°
    try:
        sse_indices = pro.index_basic(market='SSE')
        time.sleep(1.2)  # APIé¢‘ç‡æ§åˆ¶ï¼šæ¯åˆ†é’Ÿä¸è¶…è¿‡50æ¬¡
        if not sse_indices.empty:
            for _, idx in sse_indices.iterrows():
                all_indices.append({
                    'ts_code': idx['ts_code'],
                    'name': idx['name'],
                    'target_type': 'æŒ‡æ•°',
                    'category': 'æŒ‡æ•°'
                })
            logger.info(f"è·å–ä¸Šäº¤æ‰€æŒ‡æ•° {len(sse_indices)} ä¸ª")
    except Exception as e:
        logger.warning(f"è·å–ä¸Šäº¤æ‰€æŒ‡æ•°å¤±è´¥: {e}")
    
    # æ·±äº¤æ‰€æŒ‡æ•°
    try:
        szse_indices = pro.index_basic(market='SZSE')
        time.sleep(1.2)  # APIé¢‘ç‡æ§åˆ¶ï¼šæ¯åˆ†é’Ÿä¸è¶…è¿‡50æ¬¡
        if not szse_indices.empty:
            for _, idx in szse_indices.iterrows():
                all_indices.append({
                    'ts_code': idx['ts_code'],
                    'name': idx['name'],
                    'target_type': 'æŒ‡æ•°',
                    'category': 'æŒ‡æ•°'
                })
            logger.info(f"è·å–æ·±äº¤æ‰€æŒ‡æ•° {len(szse_indices)} ä¸ª")
    except Exception as e:
        logger.warning(f"è·å–æ·±äº¤æ‰€æŒ‡æ•°å¤±è´¥: {e}")
    
    # ä¸­è¯æŒ‡æ•°
    try:
        csi_indices = pro.index_basic(market='CSI')
        time.sleep(1.2)  # APIé¢‘ç‡æ§åˆ¶ï¼šæ¯åˆ†é’Ÿä¸è¶…è¿‡50æ¬¡
        if not csi_indices.empty:
            for _, idx in csi_indices.iterrows():
                all_indices.append({
                    'ts_code': idx['ts_code'],
                    'name': idx['name'],
                    'target_type': 'æŒ‡æ•°',
                    'category': 'æŒ‡æ•°'
                })
            logger.info(f"è·å–ä¸­è¯æŒ‡æ•° {len(csi_indices)} ä¸ª")
    except Exception as e:
        logger.warning(f"è·å–ä¸­è¯æŒ‡æ•°å¤±è´¥: {e}")
    
    # å›½è¯æŒ‡æ•°
    try:
        cni_indices = pro.index_basic(market='CNI')
        time.sleep(1.2)  # APIé¢‘ç‡æ§åˆ¶ï¼šæ¯åˆ†é’Ÿä¸è¶…è¿‡50æ¬¡
        if not cni_indices.empty:
            for _, idx in cni_indices.iterrows():
                all_indices.append({
                    'ts_code': idx['ts_code'],
                    'name': idx['name'],
                    'target_type': 'æŒ‡æ•°',
                    'category': 'æŒ‡æ•°'
                })
            logger.info(f"è·å–å›½è¯æŒ‡æ•° {len(cni_indices)} ä¸ª")
    except Exception as e:
        logger.warning(f"è·å–å›½è¯æŒ‡æ•°å¤±è´¥: {e}")
    
    if all_indices:
        df = pd.DataFrame(all_indices)
        df = df.drop_duplicates(subset=['ts_code'])  # å»é‡
        logger.info(f"è·å–å…¨éƒ¨æŒ‡æ•° {len(df)} ä¸ªï¼ˆå»é‡åï¼‰")
        return df
    else:
        return pd.DataFrame()

def update_universe():
    """æ›´æ–°ETF/æŒ‡æ•°æ± ï¼Œè·å–æ‰€æœ‰ETFå’ŒæŒ‡æ•°ä¿å­˜åˆ°config/universe.csv"""
    
    # è·å–æ‰€æœ‰ETF
    etf_df = get_all_etfs()
    
    # è·å–æ‰€æœ‰æŒ‡æ•°
    index_df = get_all_indices()
    
    # åˆå¹¶æ•°æ®
    all_targets = []
    if not etf_df.empty:
        all_targets.append(etf_df)
    if not index_df.empty:
        all_targets.append(index_df)
    
    if not all_targets:
        logger.error("æ— æ³•è·å–ä»»ä½•æ•°æ®")
        return
    
    # åˆå¹¶æ‰€æœ‰æ ‡çš„
    targets = pd.concat(all_targets, ignore_index=True)
    
    # ä¿å­˜åˆ°config/universe.csv
    base_dir = Path(__file__).resolve().parents[1]
    save_path = base_dir / "config" / "universe.csv"
    save_path.parent.mkdir(parents=True, exist_ok=True)
    
    targets.to_csv(save_path, index=False)
    
    logger.info(f"âœ… æ ‡çš„æ± å·²æ›´æ–°ï¼Œå…±{len(targets)}ä¸ªæ ‡çš„ï¼Œå·²ä¿å­˜è‡³{save_path}")
    print(f"\nğŸ“Š æ ‡çš„æ± ç»Ÿè®¡:")
    print(f"æ€»æ•°é‡: {len(targets)}")
    print(targets['target_type'].value_counts().to_string())

if __name__ == "__main__":
    update_universe()

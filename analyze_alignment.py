#!/usr/bin/env python3
"""
æ•°æ®å¯¹é½åˆ†æè„šæœ¬
åˆ†æä¸åŒæŒ‡æ•°çš„å†å²æ•°æ®é•¿åº¦å’Œæ—¶é—´å¯¹é½æƒ…å†µ
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

from engine.data_interface import DataInterface
import pandas as pd

def analyze_data_alignment():
    """åˆ†ææ•°æ®å¯¹é½æƒ…å†µ"""
    print("ğŸ” æ•°æ®å¯¹é½åˆ†æ")
    print("="*60)
    
    # åˆå§‹åŒ–æ•°æ®æ¥å£
    data_interface = DataInterface()
    
    print(f"ğŸ“‹ Universeé…ç½®: {len(data_interface.universe)}ä¸ªæ ‡çš„")
    print(f"ğŸ“… é…ç½®çš„æ—¶é—´èŒƒå›´: {data_interface.config['data']['start_date']} - {data_interface.config['data']['end_date']}")
    
    # è·å–ä»·æ ¼æ•°æ®ï¼ˆä½¿ç”¨å½“å‰çš„å¯¹é½é€»è¾‘ï¼‰
    print("\nğŸ”„ åŠ è½½ä»·æ ¼æ•°æ®...")
    price_data = data_interface.get_price_data()
    
    if price_data['close'].empty:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æ•°æ®")
        return
    
    close_data = price_data['close']
    print(f"ğŸ“Š å½“å‰æ•°æ®å½¢çŠ¶: {close_data.shape}")
    print(f"ğŸ“… å®é™…æ—¶é—´èŒƒå›´: {close_data.index.min().date()} - {close_data.index.max().date()}")
    
    # åˆ†ææ¯ä¸ªæ ‡çš„çš„æ•°æ®è¦†ç›–æƒ…å†µ
    print("\nğŸ“ˆ å„æ ‡çš„æ•°æ®è¦†ç›–åˆ†æ:")
    print("-" * 80)
    print(f"{'æ ‡çš„ä»£ç ':<15} {'æ•°æ®é‡':<8} {'èµ·å§‹æ—¥æœŸ':<12} {'ç»“æŸæ—¥æœŸ':<12} {'è¦†ç›–ç‡':<8}")
    print("-" * 80)
    
    total_days = len(close_data.index)
    coverage_stats = []
    
    for col in close_data.columns:
        valid_data = close_data[col].dropna()
        if len(valid_data) > 0:
            start_date = valid_data.index.min().date()
            end_date = valid_data.index.max().date()
            coverage = len(valid_data) / total_days
            coverage_stats.append({
                'code': col,
                'count': len(valid_data),
                'start': start_date,
                'end': end_date,
                'coverage': coverage
            })
            print(f"{col:<15} {len(valid_data):<8} {start_date} {end_date} {coverage:.1%}")
    
    # ç»Ÿè®¡åˆ†æ
    if coverage_stats:
        coverage_values = [s['coverage'] for s in coverage_stats]
        print(f"\nğŸ“Š è¦†ç›–ç‡ç»Ÿè®¡:")
        print(f"   å¹³å‡è¦†ç›–ç‡: {sum(coverage_values)/len(coverage_values):.1%}")
        print(f"   æœ€ä½è¦†ç›–ç‡: {min(coverage_values):.1%}")
        print(f"   æœ€é«˜è¦†ç›–ç‡: {max(coverage_values):.1%}")
        
        # æ‰¾å‡ºè¦†ç›–ç‡è¾ƒä½çš„æ ‡çš„
        low_coverage = [s for s in coverage_stats if s['coverage'] < 0.5]
        if low_coverage:
            print(f"\nâš ï¸  è¦†ç›–ç‡ä½äº50%çš„æ ‡çš„ ({len(low_coverage)}ä¸ª):")
            for s in sorted(low_coverage, key=lambda x: x['coverage']):
                print(f"   {s['code']}: {s['coverage']:.1%} ({s['count']}å¤©, {s['start']}èµ·)")
    
    # åˆ†æç¼ºå¤±æ•°æ®æ¨¡å¼
    print(f"\nğŸ•³ï¸  ç¼ºå¤±æ•°æ®åˆ†æ:")
    missing_by_date = close_data.isna().sum(axis=1)
    non_zero_missing = missing_by_date[missing_by_date > 0]
    
    if len(non_zero_missing) > 0:
        print(f"   æœ‰ç¼ºå¤±æ•°æ®çš„æ—¥æœŸ: {len(non_zero_missing)}å¤©")
        print(f"   å¹³å‡æ¯æ—¥ç¼ºå¤±: {non_zero_missing.mean():.1f}ä¸ªæ ‡çš„")
        print(f"   æœ€å¤šç¼ºå¤±: {non_zero_missing.max()}ä¸ªæ ‡çš„")
        
        # æ˜¾ç¤ºç¼ºå¤±æœ€å¤šçš„å‡ ä¸ªæ—¥æœŸ
        top_missing = non_zero_missing.nlargest(5)
        print(f"   ç¼ºå¤±æœ€å¤šçš„æ—¥æœŸ:")
        for date, count in top_missing.items():
            print(f"     {date.date()}: {count}ä¸ªæ ‡çš„ç¼ºå¤±")
    else:
        print("   âœ… æ‰€æœ‰æ—¥æœŸéƒ½æ²¡æœ‰ç¼ºå¤±æ•°æ®")

if __name__ == "__main__":
    analyze_data_alignment()

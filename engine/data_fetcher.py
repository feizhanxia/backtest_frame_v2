import os, datetime as dt, warnings, tushare as ts, pandas as pd
import pyarrow.parquet as pq
import hashlib
from pathlib import Path
from dotenv import load_dotenv; load_dotenv()

# å¿½ç•¥æ¥è‡ªpandasçš„FutureWarning
warnings.filterwarnings("ignore", category=FutureWarning, module="pandas")
# å¿½ç•¥æ¥è‡ªtushareçš„FutureWarning
warnings.filterwarnings("ignore", category=FutureWarning, module="tushare")

pro = ts.pro_api(os.getenv("TUSHARE_TOKEN"))

def _get_data_hash(ts_code: str, start: str = None, end: str = None) -> str:
    """ç”Ÿæˆæ•°æ®è¯·æ±‚çš„å“ˆå¸Œæ ‡è¯†
    
    Args:
        ts_code: æ ‡çš„ä»£ç 
        start: èµ·å§‹æ—¥æœŸï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨å†å²
        end: ç»“æŸæ—¥æœŸï¼ŒNoneè¡¨ç¤ºåˆ°ä»Šå¤©
        
    Returns:
        æ•°æ®è¯·æ±‚çš„å“ˆå¸Œå­—ç¬¦ä¸²
    """
    start_str = start if start is not None else "all"
    end_str = end if end is not None else "today"
    request_str = f"{ts_code}_{start_str}_{end_str}"
    return hashlib.md5(request_str.encode()).hexdigest()[:12]

def _check_existing_data(ts_code: str, start: str = None, end: str = None, base_dir: str = None) -> pd.DataFrame:
    """æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒæ—¶é—´èŒƒå›´çš„æ•°æ®
    
    Args:
        ts_code: æ ‡çš„ä»£ç 
        start: èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDDã€‚Noneè¡¨ç¤ºä»æœ€æ—©å¼€å§‹
        end: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDDã€‚Noneè¡¨ç¤ºåˆ°ä»Šå¤©
        base_dir: åŸºç¡€ç›®å½•ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        å¦‚æœå­˜åœ¨ä¸”ç¬¦åˆè¦æ±‚ï¼Œè¿”å›ç°æœ‰æ•°æ®ï¼›å¦åˆ™è¿”å›ç©ºDataFrame
    """
    if base_dir is None:
        # é»˜è®¤æŸ¥æ‰¾å½“å‰å·¥ä½œç›®å½•çš„processedæ•°æ®
        base_dir = Path.cwd()
    
    processed_path = Path(base_dir) / "data" / "processed" / f"{ts_code}.parquet"
    
    if not processed_path.exists():
        return pd.DataFrame()
    
    try:
        existing_df = pq.read_table(processed_path).to_pandas()
        if existing_df.empty:
            return pd.DataFrame()
        
        # ç¡®ä¿ç´¢å¼•æ˜¯datetimeç±»å‹
        if not isinstance(existing_df.index, pd.DatetimeIndex):
            existing_df.index = pd.to_datetime(existing_df.index)
        
        # è®¾ç½®é»˜è®¤ç»“æŸæ—¥æœŸä¸ºä»Šå¤©
        if end is None:
            import datetime as dt
            end = dt.date.today().strftime("%Y%m%d")
        
        end_date = pd.to_datetime(end, format='%Y%m%d')
        
        # æ£€æŸ¥ç°æœ‰æ•°æ®çš„æ—¶é—´èŒƒå›´
        data_start = existing_df.index.min()
        data_end = existing_df.index.max()
        
        # å¦‚æœstartä¸ºNoneï¼Œè¡¨ç¤ºè¦è·å–å…¨éƒ¨å†å²æ•°æ®ï¼Œä¸æ£€æŸ¥èµ·å§‹æ—¥æœŸ
        if start is None:
            # åªæ£€æŸ¥ç»“æŸæ—¥æœŸï¼šç°æœ‰æ•°æ®åº”è¯¥è¶³å¤Ÿæ–°ï¼ˆæœ€å¤šæ»å1å¤©ï¼‰
            end_gap = (end_date - data_end).days
            if end_gap <= 1:
                print(f"âœ… {ts_code} ä½¿ç”¨ç¼“å­˜æ•°æ® ({len(existing_df)}å¤©, {data_start.strftime('%Y-%m-%d')}~{data_end.strftime('%Y-%m-%d')})")
                return existing_df
            else:
                print(f"ğŸ”„ {ts_code} æ•°æ®éœ€è¦æ›´æ–° (ç°æœ‰æ•°æ®åˆ°: {data_end.strftime('%Y-%m-%d')}, éœ€è¦åˆ°: {end_date.strftime('%Y-%m-%d')})")
                return pd.DataFrame()
        else:
            # è½¬æ¢è¯·æ±‚çš„èµ·å§‹æ—¥æœŸæ ¼å¼
            start_date = pd.to_datetime(start, format='%Y%m%d')
            
            # æ£€æŸ¥æ•°æ®è¦†ç›–æƒ…å†µï¼š
            # 1. èµ·å§‹æ—¥æœŸï¼šç°æœ‰æ•°æ®å¼€å§‹æ—¥æœŸåº”è¯¥æ¥è¿‘æˆ–æ—©äºè¯·æ±‚æ—¥æœŸï¼ˆå…è®¸å‡ å¤©å·®å¼‚ï¼Œå› ä¸ºäº¤æ˜“æ—¥å†å·®å¼‚ï¼‰
            # 2. ç»“æŸæ—¥æœŸï¼šç°æœ‰æ•°æ®åº”è¯¥è¶³å¤Ÿæ–°ï¼ˆæœ€å¤šæ»å1å¤©ï¼‰
            
            start_gap = (data_start - start_date).days
            end_gap = (end_date - data_end).days
            
            # èµ·å§‹æ—¥æœŸæ£€æŸ¥ï¼šå…è®¸ç°æœ‰æ•°æ®ç¨æ™šå¼€å§‹ï¼ˆå› ä¸ºäº¤æ˜“æ—¥å†ï¼‰ï¼Œä½†ä¸è¶…è¿‡5å¤©
            start_ok = start_gap <= 5
            # ç»“æŸæ—¥æœŸæ£€æŸ¥ï¼šå…è®¸æœ€å¤šæ»å1å¤©
            end_ok = end_gap <= 1
            
            if start_ok and end_ok:
                # è¿‡æ»¤åˆ°æœ‰æ•ˆæ•°æ®èŒƒå›´
                actual_start = max(start_date, data_start)
            actual_end = min(end_date, data_end)  
            mask = (existing_df.index >= actual_start) & (existing_df.index <= actual_end)
            filtered_df = existing_df[mask]
            
            # éªŒè¯æ•°æ®è´¨é‡
            if len(filtered_df) >= 100:  # è‡³å°‘100ä¸ªäº¤æ˜“æ—¥
                print(f"âœ… {ts_code} ä½¿ç”¨ç¼“å­˜æ•°æ® ({len(filtered_df)}å¤©, {data_start.date()}~{data_end.date()})")
                return filtered_df
        
        # æ•°æ®è¦†ç›–ä¸è¶³ï¼Œéœ€è¦æ›´æ–°
        print(f"ğŸ”„ {ts_code} éœ€è¦æ›´æ–°æ•°æ® (ç°æœ‰: {data_start.date()}~{data_end.date()}, è¯·æ±‚: {start_date.date()}~{end_date.date()}, å¼€å§‹å·®{start_gap}å¤©, ç»“æŸå·®{end_gap}å¤©)")
        return pd.DataFrame()
        
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ {ts_code} ç¼“å­˜æ—¶å‡ºé”™: {e}")
        return pd.DataFrame()

def fetch_daily_with_cache(ts_code: str, start: str = None, end: str = None, asset_type: str = 'auto', 
                          base_dir: str = None, force_refresh: bool = False) -> pd.DataFrame:
    """è·å–æ—¥çº¿æ•°æ®ï¼ˆå¸¦ç¼“å­˜æ£€æŸ¥ï¼‰
    
    Args:
        ts_code: æ ‡çš„ä»£ç ï¼ˆå¦‚ï¼š000001.SZ, 510050.SH, 000300.SHï¼‰
        start: èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDDã€‚Noneè¡¨ç¤ºè·å–å…¨éƒ¨å†å²æ•°æ®
        end: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDDã€‚Noneè¡¨ç¤ºåˆ°ä»Šå¤©
        asset_type: èµ„äº§ç±»å‹ï¼Œ'stock'(è‚¡ç¥¨), 'fund'(ETF), 'index'(æŒ‡æ•°), 'auto'(è‡ªåŠ¨è¯†åˆ«)
        base_dir: åŸºç¡€ç›®å½•è·¯å¾„
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°æ•°æ®
        
    Returns:
        å‰å¤æƒåçš„æ—¥çº¿æ•°æ®ï¼Œä»¥trade_dateä¸ºç´¢å¼•
    """
    # è®¾ç½®é»˜è®¤ç»“æŸæ—¥æœŸä¸ºä»Šå¤©
    if end is None:
        import datetime as dt
        end = dt.date.today().strftime("%Y%m%d")
    
    # å¦‚æœä¸å¼ºåˆ¶åˆ·æ–°ï¼Œå…ˆæ£€æŸ¥ç°æœ‰æ•°æ®
    if not force_refresh:
        existing_data = _check_existing_data(ts_code, start, end, base_dir)
        if not existing_data.empty:
            return existing_data
    
    # æ²¡æœ‰ç¼“å­˜æˆ–éœ€è¦åˆ·æ–°ï¼Œè°ƒç”¨åŸæœ‰çš„è·å–é€»è¾‘
    print(f"ğŸ”„ {ts_code} ä»APIè·å–æ•°æ®...")
    return fetch_daily(ts_code, start, end, asset_type)

def fetch_daily(ts_code: str, start: str = None, end: str = None, asset_type: str = 'auto') -> pd.DataFrame:
    """è·å–æ—¥çº¿æ•°æ®ï¼ˆè‚¡ç¥¨/ETF/æŒ‡æ•°ï¼Œå·²å‰å¤æƒï¼‰
    
    Args:
        ts_code: æ ‡çš„ä»£ç ï¼ˆå¦‚ï¼š000001.SZ, 510050.SH, 000300.SHï¼‰
        start: èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDDã€‚Noneè¡¨ç¤ºè·å–å…¨éƒ¨å†å²æ•°æ®
        end: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDDã€‚Noneè¡¨ç¤ºåˆ°ä»Šå¤©
        asset_type: èµ„äº§ç±»å‹ï¼Œ'stock'(è‚¡ç¥¨), 'fund'(ETF), 'index'(æŒ‡æ•°), 'auto'(è‡ªåŠ¨è¯†åˆ«)
        
    Returns:
        å‰å¤æƒåçš„æ—¥çº¿æ•°æ®ï¼Œä»¥trade_dateä¸ºç´¢å¼•
    """
    try:
        # è®¾ç½®é»˜è®¤ç»“æŸæ—¥æœŸä¸ºä»Šå¤©
        if end is None:
            import datetime as dt
            end = dt.date.today().strftime("%Y%m%d")
            
        # è‡ªåŠ¨è¯†åˆ«èµ„äº§ç±»å‹
        if asset_type == 'auto':
            if ts_code.startswith(('510', '511', '512', '513', '515', '516', '518')):
                asset_type = 'fund'  # ETF
            elif (ts_code.startswith(('000', '399')) and ('SH' in ts_code or 'SZ' in ts_code)) or \
                 (ts_code.endswith('.CSI')):
                # æŒ‡æ•°ï¼ˆ000300.SH, 399001.SZ, 932000.CSIç­‰ï¼‰
                asset_type = 'index'
            else:
                asset_type = 'stock'  # é»˜è®¤ä¸ºè‚¡ç¥¨
        
        # æ ¹æ®èµ„äº§ç±»å‹é€‰æ‹©åˆé€‚çš„æ¥å£
        if asset_type == 'fund':
            # ETFä½¿ç”¨fund_dailyæ¥å£
            df = pro.fund_daily(ts_code=ts_code, start_date=start, end_date=end)
            if df is None or df.empty:
                # å¤‡é€‰ï¼šä½¿ç”¨pro_baræ¥å£
                df = ts.pro_bar(ts_code=ts_code, start_date=start, end_date=end, 
                               adj='qfq', freq='D', asset='FD')
            # !TODO: ETFæ•°æ®éœ€è¦è·å–å¤æƒå› å­æ¥è¿›è¡Œé¢å¤–å¤„ç†
        elif asset_type == 'index':
            # æŒ‡æ•°ä½¿ç”¨index_dailyæ¥å£
            df = pro.index_daily(ts_code=ts_code, start_date=start, end_date=end)
            if df is None or df.empty:
                # å¤‡é€‰ï¼šä½¿ç”¨pro_baræ¥å£
                df = ts.pro_bar(ts_code=ts_code, start_date=start, end_date=end, 
                               freq='D', asset='I')
        else:
            # è‚¡ç¥¨ä½¿ç”¨åŸæœ‰é€»è¾‘
            df = ts.pro_bar(ts_code=ts_code, start_date=start, end_date=end, 
                           adj='qfq', freq='D', asset='E')
        
        # å¦‚æœä¸»è¦æ¥å£å¤±è´¥ï¼Œå°è¯•é€šç”¨pro_baræ¥å£
        if df is None or df.empty:
            print(f"è­¦å‘Šï¼šä¸»æ¥å£è·å– {ts_code} çš„æ•°æ®ä¸ºç©ºï¼Œå°è¯•é€šç”¨æ¥å£...")
            df = ts.pro_bar(ts_code=ts_code, start_date=start, end_date=end, 
                           adj='qfq', freq='D')
        
        # å¦‚æœæ•°æ®ä»ç„¶ä¸ºç©ºï¼Œåˆ™è®°å½•é”™è¯¯
        if df is None or df.empty:
            raise ValueError(f"æ— æ³•è·å– {ts_code} çš„æ—¥çº¿æ•°æ®")
            
        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
        df = df.sort_values("trade_date")
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_cols = ["open", "high", "low", "close"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"è·å–çš„æ•°æ®ç¼ºå°‘å¿…è¦çš„åˆ—ï¼š{missing_cols}")
        
        # ç¡®ä¿åŒ…å«volå’Œamountåˆ—ï¼ˆæŸäº›æŒ‡æ•°å¯èƒ½æ²¡æœ‰ï¼‰
        if 'vol' not in df.columns:
            df['vol'] = 0  # æŒ‡æ•°æ²¡æœ‰æˆäº¤é‡ï¼Œè®¾ä¸º0
        if 'amount' not in df.columns:
            df['amount'] = 0  # æŒ‡æ•°æ²¡æœ‰æˆäº¤é¢ï¼Œè®¾ä¸º0
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        df["trade_date"] = pd.to_datetime(df["trade_date"])
        
        # æå–éœ€è¦çš„åˆ—å¹¶è¿”å›
        return df.set_index("trade_date")
    except Exception as e:
        print(f"è·å– {ts_code} çš„æ—¥çº¿æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        # åˆ›å»ºä¸€ä¸ªç©ºçš„DataFrameä½œä¸ºæ›¿ä»£
        return pd.DataFrame(columns=["ts_code", "open", "high", "low", "close", "vol", "amount"])

# åˆ é™¤è´¢åŠ¡æ•°æ®è·å–å‡½æ•°ï¼ŒETF/æŒ‡æ•°ä¸éœ€è¦è´¢åŠ¡æ•°æ®
# def fetch_financial() å‡½æ•°å·²ç§»é™¤
